{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f240302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da2496",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501bfcf",
   "metadata": {},
   "source": [
    "For object detection we are using You Only Look Once (YOLO) v5 with meduim size weight. The model is loaded directly from torch hub with the weights already trained on MS COCO dataset. \n",
    "\n",
    "The main concept behind YOLO is passing th full image to a single nueral network and letting the network decide the the regions and predict bounding boxes and probablity for each region. The following approach make it faster than even Fast R-CNN.\n",
    "\n",
    "Here, we used YOLO to detect the sports ball with standard confidence threshold of 0.25. Then all the detected regions are passed through a non-maximum suppression (NMS) on the boxes according to their intersection-over-union (IoU). We set IoU threshold to 0.45. The model returns the confidence score accompanied by ```(xmin,ymin)``` and ```(xmax,ymax)``` for each bounding box for each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59257a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2022-11-20 Python-3.9.13 torch-1.13.0+cu117 CUDA:0 (NVIDIA GeForce MX130, 4046MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5m.pt to yolov5m.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b079acabbaa40af9b673c246b5be850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/40.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', verbose=False)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863fa67",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9773083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction(img: np.ndarray,\n",
    "                    class_name: str,\n",
    "                    df: pd.core.series.Series,\n",
    "                    color: tuple = (255, 0, 0)):\n",
    "    '''\n",
    "    Function to draw prediction around the bounding box identified by the YOLO\n",
    "    The Function also displays the confidence score top of the bounding box \n",
    "    '''\n",
    "\n",
    "    cv2.rectangle(img, (int(df.xmin), int(df.ymin)),\n",
    "                  (int(df.xmax), int(df.ymax)), color, 2)\n",
    "    cv2.putText(img, class_name + \" \" + str(round(df.confidence, 2)),\n",
    "                (int(df.xmin) - 10, int(df.ymin) - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42670282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_to_frame(path: str):\n",
    "    '''\n",
    "    The function take input as video file and returns a list of images for every video\n",
    "    '''\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    img = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            img.append(frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    return img, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53c1e20",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87a2a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Video to image frame by frame for a single and multiple ball\n",
    "\n",
    "img_multi, fps_multi = convert_video_to_frame('./multiple_balls.avi')\n",
    "img_sin, fps_sin = convert_video_to_frame('./single_ball.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb429b8",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48706b9d",
   "metadata": {},
   "source": [
    "Running the model on single ball and multiple ball video respectively\n",
    "\n",
    "Storing the results in form of pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b406e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sin = model(img_sin)\n",
    "results_multi = model(img_multi)\n",
    "\n",
    "df_sin = results_sin.pandas().xyxy\n",
    "df_multi = results_multi.pandas().xyxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32ac03",
   "metadata": {},
   "source": [
    "# Kalman Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f300e8",
   "metadata": {},
   "source": [
    "Below, we init the Kalman filter class. The Kalman filter basically comprises of the following five equations\n",
    "\n",
    "- State Correction Equation(S)\n",
    "- Predicting next state(S_pred)\n",
    "- Kalman Gain Equation(K)\n",
    "- Estimate Correction Equation(P)\n",
    "- Predicting next uncertainity(P_pred)\n",
    "\n",
    "For the following problem, we assume the state to be $[x,x',x'',y,y',y'']$ where $x'$ and $x''$ denotes acceleration and velocity in x direction(same for y). Also, the Kalman filter takes into account the process noise as ```Q``` and measurement uncertainity as ```R``` \n",
    "\n",
    "**Note**: We are not updating the state correction equation and estimate uncertainity correction equation in case no ball is detected in the frame. In that case we are predicting the next state on the basis of the previous state in which ball is shown(which would be the case mathematically)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a83ee",
   "metadata": {},
   "source": [
    "## Custom Kalman Filter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6ae344",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter():\n",
    "    def __init__(self,\n",
    "                 xinit: int = 0,\n",
    "                 yinit: int = 0,\n",
    "                 fps: int = 30,\n",
    "                 std_a: float = 0.001,\n",
    "                 std_x: float = 0.0045,\n",
    "                 std_y: float = 0.01,\n",
    "                 cov: float = 100000) -> None:\n",
    "\n",
    "        # State Matrix\n",
    "        self.S = np.array([xinit, 0, 0, yinit, 0, 0])\n",
    "        self.dt = 1 / fps\n",
    "\n",
    "        # State Transition Model\n",
    "        # Here, we assume that the model follow Newtonian Kinematics\n",
    "        self.F = np.array([[1, self.dt, 0.5 * (self.dt * self.dt), 0, 0, 0],\n",
    "                           [0, 1, self.dt, 0, 0, 0], [0, 0, 1, 0, 0, 0],\n",
    "                           [0, 0, 0, 1, self.dt, 0.5 * self.dt * self.dt],\n",
    "                           [0, 0, 0, 0, 1, self.dt], [0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "        self.std_a = std_a\n",
    "\n",
    "        # Process Noise\n",
    "        self.Q = np.array([\n",
    "            [\n",
    "                0.25 * self.dt * self.dt * self.dt * self.dt, 0.5 * self.dt *\n",
    "                self.dt * self.dt, 0.5 * self.dt * self.dt, 0, 0, 0\n",
    "            ],\n",
    "            [\n",
    "                0.5 * self.dt * self.dt * self.dt, self.dt * self.dt, self.dt,\n",
    "                0, 0, 0\n",
    "            ], [0.5 * self.dt * self.dt, self.dt, 1, 0, 0, 0],\n",
    "            [\n",
    "                0, 0, 0, 0.25 * self.dt * self.dt * self.dt * self.dt,\n",
    "                0.5 * self.dt * self.dt * self.dt, 0.5 * self.dt * self.dt\n",
    "            ],\n",
    "            [\n",
    "                0, 0, 0, 0.5 * self.dt * self.dt * self.dt, self.dt * self.dt,\n",
    "                self.dt\n",
    "            ], [0, 0, 0, 0.5 * self.dt * self.dt, self.dt, 1]\n",
    "        ]) * self.std_a * self.std_a\n",
    "\n",
    "        self.std_x = std_x\n",
    "        self.std_y = std_y\n",
    "\n",
    "        # Measurement Noise\n",
    "        self.R = np.array([[self.std_x * self.std_x, 0],\n",
    "                           [0, self.std_y * self.std_y]])\n",
    "\n",
    "        self.cov = cov\n",
    "\n",
    "        # Estimate Uncertainity\n",
    "        self.P = np.array([[self.cov, 0, 0, 0, 0, 0],\n",
    "                           [0, self.cov, 0, 0, 0, 0],\n",
    "                           [0, 0, self.cov, 0, 0, 0],\n",
    "                           [0, 0, 0, self.cov, 0, 0],\n",
    "                           [0, 0, 0, 0, self.cov, 0],\n",
    "                           [0, 0, 0, 0, 0, self.cov]])\n",
    "\n",
    "        # Observation Matrix\n",
    "        # Here, we are observing X & Y (0th index and 3rd Index)\n",
    "        self.H = np.array([[1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]])\n",
    "\n",
    "        self.I = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0],\n",
    "                           [0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0],\n",
    "                           [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "        # Predicting the next state and estimate uncertainity\n",
    "        self.S_pred = None\n",
    "        self.P_pred = None\n",
    "\n",
    "        # Kalman Gain\n",
    "        self.K = None\n",
    "\n",
    "        # Storing all the State, Kalman Gain and Estimate Uncertainity\n",
    "        self.S_hist = [self.S]\n",
    "        self.K_hist = []\n",
    "        self.P_hist = [self.P]\n",
    "\n",
    "    def pred_new_state(self):\n",
    "        self.S_pred = self.F.dot(self.S)\n",
    "\n",
    "    def pred_next_uncertainity(self):\n",
    "        self.P_pred = self.F.dot(self.P).dot(self.F.T) + self.Q\n",
    "\n",
    "    def get_Kalman_gain(self):\n",
    "        self.K = self.P_pred.dot(self.H.T).dot(\n",
    "            inv(self.H.dot(self.P_pred).dot(self.H.T) + self.R))\n",
    "        self.K_hist.append(self.K)\n",
    "\n",
    "    def state_correction(self, z):\n",
    "        if z == [None, None]:\n",
    "            self.S = self.S_pred\n",
    "        else:\n",
    "            self.S = self.S_pred + +self.K.dot(z - self.H.dot(self.S_pred))\n",
    "\n",
    "        self.S_hist.append(self.S)\n",
    "\n",
    "    def uncertainity_correction(self, z):\n",
    "        if z != [None, None]:\n",
    "            self.l1 = self.I - self.K.dot(self.H)\n",
    "            self.P = self.l1.dot(self.P_pred).dot(self.l1.T) + self.K.dot(\n",
    "                self.R).dot(self.K.T)\n",
    "        self.P_hist.append(self.P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb874f",
   "metadata": {},
   "source": [
    "### Init Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7d9fc",
   "metadata": {},
   "source": [
    "Initializing Kalman Filters for both single and multi object. In case of multiple objects we have two balls, therefore two filters are initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f027baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sin = KalmanFilter(fps=fps_sin, xinit=60,\n",
    "                          yinit=150, std_x=0.000028, std_y=0.0001)\n",
    "\n",
    "filter_multi = [\n",
    "    KalmanFilter(fps=fps_multi, xinit=60, yinit=150,\n",
    "                 std_x=0.000028, std_y=0.0001),\n",
    "    KalmanFilter(fps=fps_multi, xinit=620, yinit=150,\n",
    "                 std_x=0.000028, std_y=0.0001)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f617a",
   "metadata": {},
   "source": [
    "## Kalman Filter for single sports ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea8df6",
   "metadata": {},
   "source": [
    "### Running\n",
    "\n",
    "Running the Kalman filter for single ball video\n",
    "\n",
    "**Note**: Here Kalman filters predict the center of the bounding box which is equal to center of the ball in most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e38408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in df_sin:\n",
    "    df = df.loc[df['name'] == 'sports ball']\n",
    "    x_cen, y_cen = None, None\n",
    "\n",
    "    if len(df) > 0:\n",
    "        x_cen = (df.xmin.values[0] + df.xmax.values[0]) / 2\n",
    "        y_cen = (df.ymin.values[0] + df.ymax.values[0]) / 2\n",
    "\n",
    "    filter_sin.pred_new_state()\n",
    "    filter_sin.pred_next_uncertainity()\n",
    "    filter_sin.get_Kalman_gain()\n",
    "    filter_sin.state_correction([x_cen, y_cen])\n",
    "    filter_sin.uncertainity_correction([x_cen, y_cen])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308acd2a",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23876df5",
   "metadata": {},
   "source": [
    "Visualzing the bounding box and Kalman filter prediction. Note that the bounding box has been represented in blue color and Kalman Filter has been represented as a blue dot on the ball\n",
    "\n",
    "The resulting video is save in file ```single_ball_kalman.avi```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d63c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('single_ball_kalman.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10,\n",
    "                      (img_sin[0].shape[1], img_sin[0].shape[0]))\n",
    "\n",
    "for i in range(len(img_sin)):\n",
    "    x, y = filter_sin.S_hist[i][0], filter_sin.S_hist[i][3]\n",
    "    df = df_sin[i].loc[df_sin[i]['name'] == 'sports ball']\n",
    "    tmp_img = img_sin[i]\n",
    "\n",
    "    for j in df.index.values:\n",
    "        tmp_img = draw_prediction(tmp_img, 'Ball', df.loc[j])\n",
    "\n",
    "    tmp_img = cv2.circle(tmp_img, (math.floor(\n",
    "        filter_sin.S_hist[i][0]), math.floor(filter_sin.S_hist[i][3])),\n",
    "        radius=1,\n",
    "        color=(255, 0, 0),\n",
    "        thickness=3)\n",
    "\n",
    "    out.write(tmp_img)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828cb98",
   "metadata": {},
   "source": [
    "## Kalman Filter for Multiple Balls (2 balls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe51280",
   "metadata": {},
   "source": [
    "### Running "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eabf06",
   "metadata": {},
   "source": [
    "Running the Kalman filter for multiple ball video\n",
    "\n",
    "Here we used a cost function to choose the correct filter for the ball. The cost function here uses the euclidean distance for filter assignment. For multiple balls the below approach can be modified with the help of hungarian algorithm.\n",
    "\n",
    "**Note**: Here Kalman filters predict the center of the bounding box which is equal to center of the ball in most cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cd737c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(a, b):\n",
    "    '''\n",
    "    Cost function for filter Assignment\n",
    "    Uses euclidean distance for choosing the filter\n",
    "    '''\n",
    "\n",
    "    sm = 0\n",
    "    for i in range(len(a)):\n",
    "        sm += (a[i] - b[i])**2\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d9bfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assig = []\n",
    "\n",
    "for df in df_multi:\n",
    "    df = df.loc[df['name'] == 'sports ball']\n",
    "    x_cen, y_cen = [None, None], [None, None]\n",
    "\n",
    "    for i in df.index.values:\n",
    "        coord = [(df.at[i, 'xmin'] + df.at[i, 'xmax']) / 2,\n",
    "                 (df.at[i, 'ymin'] + df.at[i, 'ymax']) / 2]\n",
    "\n",
    "        if cost_fun([\n",
    "                filter_multi[0].S_hist[-1][0], filter_multi[0].S_hist[-1][3]\n",
    "        ], coord) < cost_fun(\n",
    "            [filter_multi[1].S_hist[-1][0], filter_multi[1].S_hist[-1][3]],\n",
    "                coord) and x_cen[0] == None and y_cen[0] == None:\n",
    "            x_cen[0], y_cen[0] = coord[0], coord[1]\n",
    "            assig.append(0)\n",
    "        else:\n",
    "            x_cen[1], y_cen[1] = coord[0], coord[1]\n",
    "            assig.append(1)\n",
    "\n",
    "    for i in range(2):\n",
    "        filter_multi[i].pred_new_state()\n",
    "        filter_multi[i].pred_next_uncertainity()\n",
    "        filter_multi[i].get_Kalman_gain()\n",
    "        filter_multi[i].state_correction([x_cen[i], y_cen[i]])\n",
    "        filter_multi[i].uncertainity_correction([x_cen[i], y_cen[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b8c33f",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1eb2d4",
   "metadata": {},
   "source": [
    "Visualzing the bounding box and Kalman filter prediction. Note that the bounding box has been represented in blue color and Kalman Filter has been represented as a blue dot on the ball\n",
    "\n",
    "The resulting video is save in file ```multiple_balls_kalman.avi```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d3febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "out = cv2.VideoWriter('multiple_balls_kalman.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10,\n",
    "                      (img_multi[0].shape[1], img_multi[0].shape[0]))\n",
    "\n",
    "for i in range(len(img_multi)):\n",
    "    tmp_img = img_multi[i]\n",
    "    df = df_multi[i].loc[df_multi[i]['name'] == 'sports ball']\n",
    "\n",
    "    tmp_img = cv2.circle(tmp_img, (math.floor(filter_multi[0].S_hist[i][0]),\n",
    "                                   math.floor(filter_multi[0].S_hist[i][3])),\n",
    "                         radius=1,\n",
    "                         color=(255, 0, 0),\n",
    "                         thickness=3)\n",
    "    tmp_img = cv2.circle(tmp_img, (math.floor(filter_multi[1].S_hist[i][0]),\n",
    "                                   math.floor(filter_multi[1].S_hist[i][3])),\n",
    "                         radius=1,\n",
    "                         color=(0, 0, 255),\n",
    "                         thickness=3)\n",
    "\n",
    "    for j in df.index.values:\n",
    "        if assig[ind] == 0:\n",
    "            tmp_img = draw_prediction(tmp_img,\n",
    "                                      'Ball 1',\n",
    "                                      df.loc[j],\n",
    "                                      color=(255, 0, 0))\n",
    "        else:\n",
    "            tmp_img = draw_prediction(tmp_img,\n",
    "                                      'Ball 2',\n",
    "                                      df.loc[j],\n",
    "                                      color=(0, 0, 255))\n",
    "        ind += 1\n",
    "\n",
    "    out.write(tmp_img)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fe1c029da5ddfa442bedaee2f3b9d58474a527b1fedb47af30b8381d5ebbc3fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
